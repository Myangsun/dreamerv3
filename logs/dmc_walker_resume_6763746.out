=== Resuming DMC Walker Walk Training ===
Job ID: 6763746
Logdir: ./logdir/dreamer/dmc_walker_walk_20251129_211920
Start time: Sun Nov 30 11:15:06 EST 2025

=== Verifying GPU ===
Devices: [CudaDevice(id=0)]

---  ___                           __   ______ ---
--- |   \ _ _ ___ __ _ _ __  ___ _ \ \ / /__ / ---
--- | |) | '_/ -_) _` | '  \/ -_) '/\ V / |_ \ ---
--- |___/|_| \___\__,_|_|_|_\___|_|  \_/ |___/ ---
Replica: 0 / 1
Logdir: logdir/dreamer/dmc_walker_walk_20251129_211920
Run script: train
Observations
  is_first         Space(bool, shape=(), low=False, high=True)
  is_last          Space(bool, shape=(), low=False, high=True)
  is_terminal      Space(bool, shape=(), low=False, high=True)
  reward           Space(float32, shape=(), low=-inf, high=inf)
  image            Space(uint8, shape=(64, 64, 3), low=0, high=255)
Actions
  action           Space(float32, shape=(6,), low=-1.0, high=1.0)
Extras
  consec           Space(int32, shape=(), low=-2147483648, high=2147483647)
  stepid           Space(uint8, shape=(20,), low=0, high=255)
  dyn/deter        Space(float32, shape=(8192,), low=-inf, high=inf)
  dyn/stoch        Space(float32, shape=(32, 64), low=-inf, high=inf)
JAX devices (1): [cuda:0]
Policy devices: cuda:0
Train devices:  cuda:0
Initializing parameters...
Optimizer opt has 165,948,686 params:
    95,483,904 dyn
    20,282,115 dec
    12,850,431 val
    12,601,356 pol
    10,749,183 rew
    10,488,833 con
     3,492,864 enc
[1]
[0]
[1]
[1]
con/head/logit/bias
[1]
[1]
con/head/logit/kernel
[1]
[1]
con/mlp/linear0/bias
[1]
[1]
con/mlp/linear0/kernel
[1]
[1]
con/mlp/norm0/scale
[1]
[1]
dec/conv0/bias
[1]
[1]
dec/conv0/kernel
[1]
[1]
dec/conv0norm/scale
[1]
[1]
dec/conv1/bias
[1]
[1]
dec/conv1/kernel
[1]
[1]
dec/conv1norm/scale
[1]
[1]
dec/conv2/bias
[1]
[1]
dec/conv2/kernel
[1]
[1]
dec/conv2norm/scale
[1]
[1]
dec/imgout/bias
[1]
[1]
dec/imgout/kernel
[1]
[1]
dec/sp0/bias
[1]
[1]
dec/sp0/kernel
[1]
[1]
dec/sp1/bias
[1]
[1]
dec/sp1/kernel
[1]
[1]
dec/sp1norm/scale
[1]
[1]
dec/sp2/bias
[1]
[1]
dec/sp2/kernel
[1]
[1]
dec/spnorm/scale
[1]
[1]
dyn/dyngru/bias
[1]
[1]
dyn/dyngru/kernel
[1]
[1]
dyn/dynhid0/bias
[1]
[1]
dyn/dynhid0/kernel
[1]
[1]
dyn/dynhid0norm/scale
[1]
[1]
dyn/dynin0/bias
[1]
[1]
dyn/dynin0/kernel
[1]
[1]
dyn/dynin0norm/scale
[1]
[1]
dyn/dynin1/bias
[1]
[1]
dyn/dynin1/kernel
[1]
[1]
dyn/dynin1norm/scale
[1]
[1]
dyn/dynin2/bias
[1]
[1]
dyn/dynin2/kernel
[1]
[1]
dyn/dynin2norm/scale
[1]
[1]
dyn/obs0/bias
[1]
[1]
dyn/obs0/kernel
[1]
[1]
dyn/obs0norm/scale
[1]
[1]
dyn/obslogit/bias
[1]
[1]
dyn/obslogit/kernel
[1]
[1]
dyn/prior0/bias
[1]
[1]
dyn/prior0/kernel
[1]
[1]
dyn/prior0norm/scale
[1]
[1]
dyn/prior1/bias
[1]
[1]
dyn/prior1/kernel
[1]
[1]
dyn/prior1norm/scale
[1]
[1]
dyn/priorlogit/bias
[1]
[1]
dyn/priorlogit/kernel
[1]
[1]
enc/cnn0/bias
[1]
[1]
enc/cnn0/kernel
[1]
[1]
enc/cnn0norm/scale
[1]
[1]
enc/cnn1/bias
[1]
[1]
enc/cnn1/kernel
[1]
[1]
enc/cnn1norm/scale
[1]
[1]
enc/cnn2/bias
[1]
[1]
enc/cnn2/kernel
[1]
[1]
enc/cnn2norm/scale
[1]
[1]
enc/cnn3/bias
[1]
[1]
enc/cnn3/kernel
[1]
[1]
enc/cnn3norm/scale
[1]
[1]
pol/head/action/mean/bias
[1]
[1]
pol/head/action/mean/kernel
[1]
[1]
pol/head/action/stddev/bias
[1]
[1]
pol/head/action/stddev/kernel
[1]
[1]
pol/mlp/linear0/bias
[1]
[1]
pol/mlp/linear0/kernel
[1]
[1]
pol/mlp/linear1/bias
[1]
[1]
pol/mlp/linear1/kernel
[1]
[1]
pol/mlp/linear2/bias
[1]
[1]
pol/mlp/linear2/kernel
[1]
[1]
pol/mlp/norm0/scale
[1]
[1]
pol/mlp/norm1/scale
[1]
[1]
pol/mlp/norm2/scale
[1]
[1]
rew/head/logits/bias
[1]
[1]
rew/head/logits/kernel
[1]
[1]
rew/mlp/linear0/bias
[1]
[1]
rew/mlp/linear0/kernel
[1]
[1]
rew/mlp/norm0/scale
[1]
[1]
val/head/logits/bias
[1]
[1]
val/head/logits/kernel
[1]
[1]
val/mlp/linear0/bias
[1]
[1]
val/mlp/linear0/kernel
[1]
[1]
val/mlp/linear1/bias
[1]
[1]
val/mlp/linear1/kernel
[1]
[1]
val/mlp/linear2/bias
[1]
[1]
val/mlp/linear2/kernel
[1]
[1]
val/mlp/norm0/scale
[1]
[1]
val/mlp/norm1/scale
[1]
[1]
val/mlp/norm2/scale
[2]
[0]
[2]
[1]
con/head/logit/bias
[2]
[1]
con/head/logit/kernel
[2]
[1]
con/mlp/linear0/bias
[2]
[1]
con/mlp/linear0/kernel
[2]
[1]
con/mlp/norm0/scale
[2]
[1]
dec/conv0/bias
[2]
[1]
dec/conv0/kernel
[2]
[1]
dec/conv0norm/scale
[2]
[1]
dec/conv1/bias
[2]
[1]
dec/conv1/kernel
[2]
[1]
dec/conv1norm/scale
[2]
[1]
dec/conv2/bias
[2]
[1]
dec/conv2/kernel
[2]
[1]
dec/conv2norm/scale
[2]
[1]
dec/imgout/bias
[2]
[1]
dec/imgout/kernel
[2]
[1]
dec/sp0/bias
[2]
[1]
dec/sp0/kernel
[2]
[1]
dec/sp1/bias
[2]
[1]
dec/sp1/kernel
[2]
[1]
dec/sp1norm/scale
[2]
[1]
dec/sp2/bias
[2]
[1]
dec/sp2/kernel
[2]
[1]
dec/spnorm/scale
[2]
[1]
dyn/dyngru/bias
[2]
[1]
dyn/dyngru/kernel
[2]
[1]
dyn/dynhid0/bias
[2]
[1]
dyn/dynhid0/kernel
[2]
[1]
dyn/dynhid0norm/scale
[2]
[1]
dyn/dynin0/bias
[2]
[1]
dyn/dynin0/kernel
[2]
[1]
dyn/dynin0norm/scale
[2]
[1]
dyn/dynin1/bias
[2]
[1]
dyn/dynin1/kernel
[2]
[1]
dyn/dynin1norm/scale
[2]
[1]
dyn/dynin2/bias
[2]
[1]
dyn/dynin2/kernel
[2]
[1]
dyn/dynin2norm/scale
[2]
[1]
dyn/obs0/bias
[2]
[1]
dyn/obs0/kernel
[2]
[1]
dyn/obs0norm/scale
[2]
[1]
dyn/obslogit/bias
[2]
[1]
dyn/obslogit/kernel
[2]
[1]
dyn/prior0/bias
[2]
[1]
dyn/prior0/kernel
[2]
[1]
dyn/prior0norm/scale
[2]
[1]
dyn/prior1/bias
[2]
[1]
dyn/prior1/kernel
[2]
[1]
dyn/prior1norm/scale
[2]
[1]
dyn/priorlogit/bias
[2]
[1]
dyn/priorlogit/kernel
[2]
[1]
enc/cnn0/bias
[2]
[1]
enc/cnn0/kernel
[2]
[1]
enc/cnn0norm/scale
[2]
[1]
enc/cnn1/bias
[2]
[1]
enc/cnn1/kernel
[2]
[1]
enc/cnn1norm/scale
[2]
[1]
enc/cnn2/bias
[2]
[1]
enc/cnn2/kernel
[2]
[1]
enc/cnn2norm/scale
[2]
[1]
enc/cnn3/bias
[2]
[1]
enc/cnn3/kernel
[2]
[1]
enc/cnn3norm/scale
[2]
[1]
pol/head/action/mean/bias
[2]
[1]
pol/head/action/mean/kernel
[2]
[1]
pol/head/action/stddev/bias
[2]
[1]
pol/head/action/stddev/kernel
[2]
[1]
pol/mlp/linear0/bias
[2]
[1]
pol/mlp/linear0/kernel
[2]
[1]
pol/mlp/linear1/bias
[2]
[1]
pol/mlp/linear1/kernel
[2]
[1]
pol/mlp/linear2/bias
[2]
[1]
pol/mlp/linear2/kernel
[2]
[1]
pol/mlp/norm0/scale
[2]
[1]
pol/mlp/norm1/scale
[2]
[1]
pol/mlp/norm2/scale
[2]
[1]
rew/head/logits/bias
[2]
[1]
rew/head/logits/kernel
[2]
[1]
rew/mlp/linear0/bias
[2]
[1]
rew/mlp/linear0/kernel
[2]
[1]
rew/mlp/norm0/scale
[2]
[1]
val/head/logits/bias
[2]
[1]
val/head/logits/kernel
[2]
[1]
val/mlp/linear0/bias
[2]
[1]
val/mlp/linear0/kernel
[2]
[1]
val/mlp/linear1/bias
[2]
[1]
val/mlp/linear1/kernel
[2]
[1]
val/mlp/linear2/bias
[2]
[1]
val/mlp/linear2/kernel
[2]
[1]
val/mlp/norm0/scale
[2]
[1]
val/mlp/norm1/scale
[2]
[1]
val/mlp/norm2/scale
[3]
.count
[1]
[0]
[1]
[1]
con/head/logit/bias
[1]
[1]
con/head/logit/kernel
[1]
[1]
con/mlp/linear0/bias
[1]
[1]
con/mlp/linear0/kernel
[1]
[1]
con/mlp/norm0/scale
[1]
[1]
dec/conv0/bias
[1]
[1]
dec/conv0/kernel
[1]
[1]
dec/conv0norm/scale
[1]
[1]
dec/conv1/bias
[1]
[1]
dec/conv1/kernel
[1]
[1]
dec/conv1norm/scale
[1]
[1]
dec/conv2/bias
[1]
[1]
dec/conv2/kernel
[1]
[1]
dec/conv2norm/scale
[1]
[1]
dec/imgout/bias
[1]
[1]
dec/imgout/kernel
[1]
[1]
dec/sp0/bias
[1]
[1]
dec/sp0/kernel
[1]
[1]
dec/sp1/bias
[1]
[1]
dec/sp1/kernel
[1]
[1]
dec/sp1norm/scale
[1]
[1]
dec/sp2/bias
[1]
[1]
dec/sp2/kernel
[1]
[1]
dec/spnorm/scale
[1]
[1]
dyn/dyngru/bias
[1]
[1]
dyn/dyngru/kernel
[1]
[1]
dyn/dynhid0/bias
[1]
[1]
dyn/dynhid0/kernel
[1]
[1]
dyn/dynhid0norm/scale
[1]
[1]
dyn/dynin0/bias
[1]
[1]
dyn/dynin0/kernel
[1]
[1]
dyn/dynin0norm/scale
[1]
[1]
dyn/dynin1/bias
[1]
[1]
dyn/dynin1/kernel
[1]
[1]
dyn/dynin1norm/scale
[1]
[1]
dyn/dynin2/bias
[1]
[1]
dyn/dynin2/kernel
[1]
[1]
dyn/dynin2norm/scale
[1]
[1]
dyn/obs0/bias
[1]
[1]
dyn/obs0/kernel
[1]
[1]
dyn/obs0norm/scale
[1]
[1]
dyn/obslogit/bias
[1]
[1]
dyn/obslogit/kernel
[1]
[1]
dyn/prior0/bias
[1]
[1]
dyn/prior0/kernel
[1]
[1]
dyn/prior0norm/scale
[1]
[1]
dyn/prior1/bias
[1]
[1]
dyn/prior1/kernel
[1]
[1]
dyn/prior1norm/scale
[1]
[1]
dyn/priorlogit/bias
[1]
[1]
dyn/priorlogit/kernel
[1]
[1]
enc/cnn0/bias
[1]
[1]
enc/cnn0/kernel
[1]
[1]
enc/cnn0norm/scale
[1]
[1]
enc/cnn1/bias
[1]
[1]
enc/cnn1/kernel
[1]
[1]
enc/cnn1norm/scale
[1]
[1]
enc/cnn2/bias
[1]
[1]
enc/cnn2/kernel
[1]
[1]
enc/cnn2norm/scale
[1]
[1]
enc/cnn3/bias
[1]
[1]
enc/cnn3/kernel
[1]
[1]
enc/cnn3norm/scale
[1]
[1]
pol/head/action/mean/bias
[1]
[1]
pol/head/action/mean/kernel
[1]
[1]
pol/head/action/stddev/bias
[1]
[1]
pol/head/action/stddev/kernel
[1]
[1]
pol/mlp/linear0/bias
[1]
[1]
pol/mlp/linear0/kernel
[1]
[1]
pol/mlp/linear1/bias
[1]
[1]
pol/mlp/linear1/kernel
[1]
[1]
pol/mlp/linear2/bias
[1]
[1]
pol/mlp/linear2/kernel
[1]
[1]
pol/mlp/norm0/scale
[1]
[1]
pol/mlp/norm1/scale
[1]
[1]
pol/mlp/norm2/scale
[1]
[1]
rew/head/logits/bias
[1]
[1]
rew/head/logits/kernel
[1]
[1]
rew/mlp/linear0/bias
[1]
[1]
rew/mlp/linear0/kernel
[1]
[1]
rew/mlp/norm0/scale
[1]
[1]
val/head/logits/bias
[1]
[1]
val/head/logits/kernel
[1]
[1]
val/mlp/linear0/bias
[1]
[1]
val/mlp/linear0/kernel
[1]
[1]
val/mlp/linear1/bias
[1]
[1]
val/mlp/linear1/kernel
[1]
[1]
val/mlp/linear2/bias
[1]
[1]
val/mlp/linear2/kernel
[1]
[1]
val/mlp/norm0/scale
[1]
[1]
val/mlp/norm1/scale
[1]
[1]
val/mlp/norm2/scale
[2]
[0]
[2]
[1]
con/head/logit/bias
[2]
[1]
con/head/logit/kernel
[2]
[1]
con/mlp/linear0/bias
[2]
[1]
con/mlp/linear0/kernel
[2]
[1]
con/mlp/norm0/scale
[2]
[1]
dec/conv0/bias
[2]
[1]
dec/conv0/kernel
[2]
[1]
dec/conv0norm/scale
[2]
[1]
dec/conv1/bias
[2]
[1]
dec/conv1/kernel
[2]
[1]
dec/conv1norm/scale
[2]
[1]
dec/conv2/bias
[2]
[1]
dec/conv2/kernel
[2]
[1]
dec/conv2norm/scale
[2]
[1]
dec/imgout/bias
[2]
[1]
dec/imgout/kernel
[2]
[1]
dec/sp0/bias
[2]
[1]
dec/sp0/kernel
[2]
[1]
dec/sp1/bias
[2]
[1]
dec/sp1/kernel
[2]
[1]
dec/sp1norm/scale
[2]
[1]
dec/sp2/bias
[2]
[1]
dec/sp2/kernel
[2]
[1]
dec/spnorm/scale
[2]
[1]
dyn/dyngru/bias
[2]
[1]
dyn/dyngru/kernel
[2]
[1]
dyn/dynhid0/bias
[2]
[1]
dyn/dynhid0/kernel
[2]
[1]
dyn/dynhid0norm/scale
[2]
[1]
dyn/dynin0/bias
[2]
[1]
dyn/dynin0/kernel
[2]
[1]
dyn/dynin0norm/scale
[2]
[1]
dyn/dynin1/bias
[2]
[1]
dyn/dynin1/kernel
[2]
[1]
dyn/dynin1norm/scale
[2]
[1]
dyn/dynin2/bias
[2]
[1]
dyn/dynin2/kernel
[2]
[1]
dyn/dynin2norm/scale
[2]
[1]
dyn/obs0/bias
[2]
[1]
dyn/obs0/kernel
[2]
[1]
dyn/obs0norm/scale
[2]
[1]
dyn/obslogit/bias
[2]
[1]
dyn/obslogit/kernel
[2]
[1]
dyn/prior0/bias
[2]
[1]
dyn/prior0/kernel
[2]
[1]
dyn/prior0norm/scale
[2]
[1]
dyn/prior1/bias
[2]
[1]
dyn/prior1/kernel
[2]
[1]
dyn/prior1norm/scale
[2]
[1]
dyn/priorlogit/bias
[2]
[1]
dyn/priorlogit/kernel
[2]
[1]
enc/cnn0/bias
[2]
[1]
enc/cnn0/kernel
[2]
[1]
enc/cnn0norm/scale
[2]
[1]
enc/cnn1/bias
[2]
[1]
enc/cnn1/kernel
[2]
[1]
enc/cnn1norm/scale
[2]
[1]
enc/cnn2/bias
[2]
[1]
enc/cnn2/kernel
[2]
[1]
enc/cnn2norm/scale
[2]
[1]
enc/cnn3/bias
[2]
[1]
enc/cnn3/kernel
[2]
[1]
enc/cnn3norm/scale
[2]
[1]
pol/head/action/mean/bias
[2]
[1]
pol/head/action/mean/kernel
[2]
[1]
pol/head/action/stddev/bias
[2]
[1]
pol/head/action/stddev/kernel
[2]
[1]
pol/mlp/linear0/bias
[2]
[1]
pol/mlp/linear0/kernel
[2]
[1]
pol/mlp/linear1/bias
[2]
[1]
pol/mlp/linear1/kernel
[2]
[1]
pol/mlp/linear2/bias
[2]
[1]
pol/mlp/linear2/kernel
[2]
[1]
pol/mlp/norm0/scale
[2]
[1]
pol/mlp/norm1/scale
[2]
[1]
pol/mlp/norm2/scale
[2]
[1]
rew/head/logits/bias
[2]
[1]
rew/head/logits/kernel
[2]
[1]
rew/mlp/linear0/bias
[2]
[1]
rew/mlp/linear0/kernel
[2]
[1]
rew/mlp/norm0/scale
[2]
[1]
val/head/logits/bias
[2]
[1]
val/head/logits/kernel
[2]
[1]
val/mlp/linear0/bias
[2]
[1]
val/mlp/linear0/kernel
[2]
[1]
val/mlp/linear1/bias
[2]
[1]
val/mlp/linear1/kernel
[2]
[1]
val/mlp/linear2/bias
[2]
[1]
val/mlp/linear2/kernel
[2]
[1]
val/mlp/norm0/scale
[2]
[1]
val/mlp/norm1/scale
[2]
[1]
val/mlp/norm2/scale
[3]
.count
Done initializing!
Compiling 1 checkpoint groups...
Largest checkpoint group: 2 GB
Compiling train and report...
[1]
[0]
[1]
[1]
con/head/logit/bias
[1]
[1]
con/head/logit/kernel
[1]
[1]
con/mlp/linear0/bias
[1]
[1]
con/mlp/linear0/kernel
[1]
[1]
con/mlp/norm0/scale
[1]
[1]
dec/conv0/bias
[1]
[1]
dec/conv0/kernel
[1]
[1]
dec/conv0norm/scale
[1]
[1]
dec/conv1/bias
[1]
[1]
dec/conv1/kernel
[1]
[1]
dec/conv1norm/scale
[1]
[1]
dec/conv2/bias
[1]
[1]
dec/conv2/kernel
[1]
[1]
dec/conv2norm/scale
[1]
[1]
dec/imgout/bias
[1]
[1]
dec/imgout/kernel
[1]
[1]
dec/sp0/bias
[1]
[1]
dec/sp0/kernel
[1]
[1]
dec/sp1/bias
[1]
[1]
dec/sp1/kernel
[1]
[1]
dec/sp1norm/scale
[1]
[1]
dec/sp2/bias
[1]
[1]
dec/sp2/kernel
[1]
[1]
dec/spnorm/scale
[1]
[1]
dyn/dyngru/bias
[1]
[1]
dyn/dyngru/kernel
[1]
[1]
dyn/dynhid0/bias
[1]
[1]
dyn/dynhid0/kernel
[1]
[1]
dyn/dynhid0norm/scale
[1]
[1]
dyn/dynin0/bias
[1]
[1]
dyn/dynin0/kernel
[1]
[1]
dyn/dynin0norm/scale
[1]
[1]
dyn/dynin1/bias
[1]
[1]
dyn/dynin1/kernel
[1]
[1]
dyn/dynin1norm/scale
[1]
[1]
dyn/dynin2/bias
[1]
[1]
dyn/dynin2/kernel
[1]
[1]
dyn/dynin2norm/scale
[1]
[1]
dyn/obs0/bias
[1]
[1]
dyn/obs0/kernel
[1]
[1]
dyn/obs0norm/scale
[1]
[1]
dyn/obslogit/bias
[1]
[1]
dyn/obslogit/kernel
[1]
[1]
dyn/prior0/bias
[1]
[1]
dyn/prior0/kernel
[1]
[1]
dyn/prior0norm/scale
[1]
[1]
dyn/prior1/bias
[1]
[1]
dyn/prior1/kernel
[1]
[1]
dyn/prior1norm/scale
[1]
[1]
dyn/priorlogit/bias
[1]
[1]
dyn/priorlogit/kernel
[1]
[1]
enc/cnn0/bias
[1]
[1]
enc/cnn0/kernel
[1]
[1]
enc/cnn0norm/scale
[1]
[1]
enc/cnn1/bias
[1]
[1]
enc/cnn1/kernel
[1]
[1]
enc/cnn1norm/scale
[1]
[1]
enc/cnn2/bias
[1]
[1]
enc/cnn2/kernel
[1]
[1]
enc/cnn2norm/scale
[1]
[1]
enc/cnn3/bias
[1]
[1]
enc/cnn3/kernel
[1]
[1]
enc/cnn3norm/scale
[1]
[1]
pol/head/action/mean/bias
[1]
[1]
pol/head/action/mean/kernel
[1]
[1]
pol/head/action/stddev/bias
[1]
[1]
pol/head/action/stddev/kernel
[1]
[1]
pol/mlp/linear0/bias
[1]
[1]
pol/mlp/linear0/kernel
[1]
[1]
pol/mlp/linear1/bias
[1]
[1]
pol/mlp/linear1/kernel
[1]
[1]
pol/mlp/linear2/bias
[1]
[1]
pol/mlp/linear2/kernel
[1]
[1]
pol/mlp/norm0/scale
[1]
[1]
pol/mlp/norm1/scale
[1]
[1]
pol/mlp/norm2/scale
[1]
[1]
rew/head/logits/bias
[1]
[1]
rew/head/logits/kernel
[1]
[1]
rew/mlp/linear0/bias
[1]
[1]
rew/mlp/linear0/kernel
[1]
[1]
rew/mlp/norm0/scale
[1]
[1]
val/head/logits/bias
[1]
[1]
val/head/logits/kernel
[1]
[1]
val/mlp/linear0/bias
[1]
[1]
val/mlp/linear0/kernel
[1]
[1]
val/mlp/linear1/bias
[1]
[1]
val/mlp/linear1/kernel
[1]
[1]
val/mlp/linear2/bias
[1]
[1]
val/mlp/linear2/kernel
[1]
[1]
val/mlp/norm0/scale
[1]
[1]
val/mlp/norm1/scale
[1]
[1]
val/mlp/norm2/scale
[2]
[0]
[2]
[1]
con/head/logit/bias
[2]
[1]
con/head/logit/kernel
[2]
[1]
con/mlp/linear0/bias
[2]
[1]
con/mlp/linear0/kernel
[2]
[1]
con/mlp/norm0/scale
[2]
[1]
dec/conv0/bias
[2]
[1]
dec/conv0/kernel
[2]
[1]
dec/conv0norm/scale
[2]
[1]
dec/conv1/bias
[2]
[1]
dec/conv1/kernel
[2]
[1]
dec/conv1norm/scale
[2]
[1]
dec/conv2/bias
[2]
[1]
dec/conv2/kernel
[2]
[1]
dec/conv2norm/scale
[2]
[1]
dec/imgout/bias
[2]
[1]
dec/imgout/kernel
[2]
[1]
dec/sp0/bias
[2]
[1]
dec/sp0/kernel
[2]
[1]
dec/sp1/bias
[2]
[1]
dec/sp1/kernel
[2]
[1]
dec/sp1norm/scale
[2]
[1]
dec/sp2/bias
[2]
[1]
dec/sp2/kernel
[2]
[1]
dec/spnorm/scale
[2]
[1]
dyn/dyngru/bias
[2]
[1]
dyn/dyngru/kernel
[2]
[1]
dyn/dynhid0/bias
[2]
[1]
dyn/dynhid0/kernel
[2]
[1]
dyn/dynhid0norm/scale
[2]
[1]
dyn/dynin0/bias
[2]
[1]
dyn/dynin0/kernel
[2]
[1]
dyn/dynin0norm/scale
[2]
[1]
dyn/dynin1/bias
[2]
[1]
dyn/dynin1/kernel
[2]
[1]
dyn/dynin1norm/scale
[2]
[1]
dyn/dynin2/bias
[2]
[1]
dyn/dynin2/kernel
[2]
[1]
dyn/dynin2norm/scale
[2]
[1]
dyn/obs0/bias
[2]
[1]
dyn/obs0/kernel
[2]
[1]
dyn/obs0norm/scale
[2]
[1]
dyn/obslogit/bias
[2]
[1]
dyn/obslogit/kernel
[2]
[1]
dyn/prior0/bias
[2]
[1]
dyn/prior0/kernel
[2]
[1]
dyn/prior0norm/scale
[2]
[1]
dyn/prior1/bias
[2]
[1]
dyn/prior1/kernel
[2]
[1]
dyn/prior1norm/scale
[2]
[1]
dyn/priorlogit/bias
[2]
[1]
dyn/priorlogit/kernel
[2]
[1]
enc/cnn0/bias
[2]
[1]
enc/cnn0/kernel
[2]
[1]
enc/cnn0norm/scale
[2]
[1]
enc/cnn1/bias
[2]
[1]
enc/cnn1/kernel
[2]
[1]
enc/cnn1norm/scale
[2]
[1]
enc/cnn2/bias
[2]
[1]
enc/cnn2/kernel
[2]
[1]
enc/cnn2norm/scale
[2]
[1]
enc/cnn3/bias
[2]
[1]
enc/cnn3/kernel
[2]
[1]
enc/cnn3norm/scale
[2]
[1]
pol/head/action/mean/bias
[2]
[1]
pol/head/action/mean/kernel
[2]
[1]
pol/head/action/stddev/bias
[2]
[1]
pol/head/action/stddev/kernel
[2]
[1]
pol/mlp/linear0/bias
[2]
[1]
pol/mlp/linear0/kernel
[2]
[1]
pol/mlp/linear1/bias
[2]
[1]
pol/mlp/linear1/kernel
[2]
[1]
pol/mlp/linear2/bias
[2]
[1]
pol/mlp/linear2/kernel
[2]
[1]
pol/mlp/norm0/scale
[2]
[1]
pol/mlp/norm1/scale
[2]
[1]
pol/mlp/norm2/scale
[2]
[1]
rew/head/logits/bias
[2]
[1]
rew/head/logits/kernel
[2]
[1]
rew/mlp/linear0/bias
[2]
[1]
rew/mlp/linear0/kernel
[2]
[1]
rew/mlp/norm0/scale
[2]
[1]
val/head/logits/bias
[2]
[1]
val/head/logits/kernel
[2]
[1]
val/mlp/linear0/bias
[2]
[1]
val/mlp/linear0/kernel
[2]
[1]
val/mlp/linear1/bias
[2]
[1]
val/mlp/linear1/kernel
[2]
[1]
val/mlp/linear2/bias
[2]
[1]
val/mlp/linear2/kernel
[2]
[1]
val/mlp/norm0/scale
[2]
[1]
val/mlp/norm1/scale
[2]
[1]
val/mlp/norm2/scale
[3]
.count
Train cost analysis:
No available
Report cost analysis:
No available
Done compiling!
Found existing checkpoint.
Loading checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T030537F654851
Loaded checkpoint.
Start training loop

--------------------[Agent Step 268_304]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.91 / train/loss/image 3.97 / train/loss/policy -0.02 / train/loss/rep 3.91 / train/loss/repval 0.94 / train/loss/rew 0.6 / train/loss/value 0.86 / replay/replay_ratio 751.32 / fps/policy 11.44 / fps/train 2929.4

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 269_856]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.24 / train/loss/image 3.52 / train/loss/policy -0.02 / train/loss/rep 3.24 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.85 / replay/replay_ratio 260 / fps/policy 12.88 / fps/train 3296.14

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 271_408]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.22 / train/loss/image 3.49 / train/loss/policy -0.02 / train/loss/rep 3.22 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.85 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.57

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 272_960]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.13 / train/loss/image 3.43 / train/loss/policy -0.02 / train/loss/rep 3.13 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.85 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.51

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 274_512]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.22 / train/loss/image 3.39 / train/loss/policy -0.02 / train/loss/rep 3.22 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.85 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.66

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 276_064]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.13 / train/loss/image 3.38 / train/loss/policy -0.02 / train/loss/rep 3.13 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.85 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.16

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 277_616]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.2 / train/loss/image 3.36 / train/loss/policy -0.02 / train/loss/rep 3.2 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.53

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T113119F415692
Saved checkpoint.

--------------------[Agent Step 279_088]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.17 / train/loss/image 3.36 / train/loss/policy -0.02 / train/loss/rep 3.17 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.17 / fps/train 3114.28

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 280_640]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.22 / train/loss/image 3.36 / train/loss/policy -0.01 / train/loss/rep 3.22 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.38

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 282_192]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.15 / train/loss/image 3.35 / train/loss/policy -0.01 / train/loss/rep 3.15 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.07

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 283_744]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 955.7 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.33 / train/loss/image 3.45 / train/loss/policy -0.02 / train/loss/rep 3.33 / train/loss/repval 0.93 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.4

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 285_296]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.21 / train/loss/image 3.43 / train/loss/policy -0.01 / train/loss/rep 3.21 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.75

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 286_848]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.24 / train/loss/image 3.41 / train/loss/policy -0.01 / train/loss/rep 3.24 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.28

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 288_400]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.1 / train/loss/image 3.33 / train/loss/policy -0.02 / train/loss/rep 3.1 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.22

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T114620F623159
Saved checkpoint.

--------------------[Agent Step 289_888]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.14 / train/loss/image 3.35 / train/loss/policy -0.01 / train/loss/rep 3.14 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.25 / fps/train 3136.3

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 291_440]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.11 / train/loss/image 3.31 / train/loss/policy -0.01 / train/loss/rep 3.11 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.88 / fps/train 3298.24

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 292_992]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.17 / train/loss/image 3.3 / train/loss/policy -0.01 / train/loss/rep 3.17 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.97

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 294_544]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.15 / train/loss/image 3.29 / train/loss/policy -0.01 / train/loss/rep 3.15 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.1

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 296_096]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.13 / train/loss/image 3.28 / train/loss/policy -0.01 / train/loss/rep 3.13 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.07

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 297_648]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.14 / train/loss/image 3.28 / train/loss/policy -0.01 / train/loss/rep 3.14 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.95

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 299_200]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 951.52 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.19 / train/loss/image 3.31 / train/loss/policy -0.02 / train/loss/rep 3.19 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.88

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 300_752]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.27 / train/loss/image 3.36 / train/loss/policy -8.4e-3 / train/loss/rep 3.27 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.37

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T120121F857227
Saved checkpoint.

--------------------[Agent Step 302_224]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.16 / train/loss/image 3.3 / train/loss/policy -0.02 / train/loss/rep 3.16 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.24 / fps/train 3132.9

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 303_776]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.12 / train/loss/image 3.28 / train/loss/policy -0.02 / train/loss/rep 3.12 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.68

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 305_328]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.2 / train/loss/image 3.32 / train/loss/policy -0.01 / train/loss/rep 3.2 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.79

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 306_880]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.16 / train/loss/image 3.3 / train/loss/policy -0.01 / train/loss/rep 3.16 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.15

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 308_432]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.14 / train/loss/image 3.27 / train/loss/policy -0.01 / train/loss/rep 3.14 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.88

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 309_984]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.09 / train/loss/image 3.22 / train/loss/policy -0.01 / train/loss/rep 3.09 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.37

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 311_536]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.16 / train/loss/image 3.27 / train/loss/policy -0.01 / train/loss/rep 3.16 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3295.15

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T121622F191742
Saved checkpoint.

--------------------[Agent Step 313_024]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.14 / train/loss/image 3.23 / train/loss/policy -9.3e-3 / train/loss/rep 3.14 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.29 / fps/train 3146.85

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 314_576]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.08 / train/loss/image 3.2 / train/loss/policy -9.3e-3 / train/loss/rep 3.08 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.49

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 316_128]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 941.18 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.28 / train/loss/image 3.37 / train/loss/policy -8e-3 / train/loss/rep 3.28 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.61

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 317_680]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.26 / train/loss/policy -9.7e-3 / train/loss/rep 3.07 / train/loss/repval 0.92 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.84 / fps/train 3288.22

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 319_232]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.13 / train/loss/image 3.22 / train/loss/policy -0.01 / train/loss/rep 3.13 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.87

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 320_784]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.1 / train/loss/image 3.2 / train/loss/policy -0.01 / train/loss/rep 3.1 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.38

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 322_336]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.15 / train/loss/image 3.24 / train/loss/policy -0.02 / train/loss/rep 3.15 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3290.92

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 323_888]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.1 / train/loss/image 3.19 / train/loss/policy -0.02 / train/loss/rep 3.1 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.92

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T123122F572486
Saved checkpoint.

--------------------[Agent Step 325_376]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.12 / train/loss/image 3.19 / train/loss/policy -0.01 / train/loss/rep 3.12 / train/loss/repval 0.91 / train/loss/rew 0.6 / train/loss/value 0.84 / replay/replay_ratio 260 / fps/policy 12.3 / fps/train 3148.44

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 326_928]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.1 / train/loss/image 3.17 / train/loss/policy -0.02 / train/loss/rep 3.1 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.01

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 328_480]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.09 / train/loss/image 3.15 / train/loss/policy -0.01 / train/loss/rep 3.09 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.7

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 330_032]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.14 / train/loss/policy -0.01 / train/loss/rep 3.07 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.14

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 331_584]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 973.42 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.19 / train/loss/image 3.21 / train/loss/policy -0.01 / train/loss/rep 3.19 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.38

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 333_136]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.18 / train/loss/image 3.22 / train/loss/policy -8.3e-3 / train/loss/rep 3.18 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.32

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 334_688]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.14 / train/loss/policy -9.7e-3 / train/loss/rep 3.07 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.56

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T124623F753947
Saved checkpoint.

--------------------[Agent Step 336_160]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.11 / train/loss/image 3.16 / train/loss/policy -0.01 / train/loss/rep 3.11 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.25 / fps/train 3135.74

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 337_712]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.1 / train/loss/image 3.17 / train/loss/policy -0.01 / train/loss/rep 3.1 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.95

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl

--------------------[Agent Step 339_264]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.01 / train/loss/image 3.09 / train/loss/policy -9.7e-3 / train/loss/rep 3.01 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.92

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 340_816]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.1 / train/loss/policy -9e-3 / train/loss/rep 3.07 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.75

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 342_368]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.06 / train/loss/image 3.07 / train/loss/policy -7.2e-3 / train/loss/rep 3.06 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.59

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 343_920]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.09 / train/loss/policy -9.5e-3 / train/loss/rep 3.07 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.05

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 345_472]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.06 / train/loss/image 3.06 / train/loss/policy -8.4e-3 / train/loss/rep 3.06 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.89 / fps/train 3299.06

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 347_024]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 924.84 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.13 / train/loss/image 3.1 / train/loss/policy -0.01 / train/loss/rep 3.13 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.64

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T130124F766659
Saved checkpoint.

--------------------[Agent Step 348_512]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.17 / train/loss/image 3.19 / train/loss/policy -3.6e-3 / train/loss/rep 3.17 / train/loss/repval 0.91 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.33 / fps/train 3156.79

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 350_064]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.08 / train/loss/image 3.11 / train/loss/policy -0.01 / train/loss/rep 3.08 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.1

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 351_616]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.08 / train/loss/image 3.1 / train/loss/policy -9.7e-3 / train/loss/rep 3.08 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3291.62

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 353_168]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.05 / train/loss/image 3.07 / train/loss/policy -0.01 / train/loss/rep 3.05 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.88 / fps/train 3297.36

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 354_720]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.06 / train/loss/image 3.06 / train/loss/policy -0.01 / train/loss/rep 3.06 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.89 / fps/train 3299

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 356_272]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.08 / train/loss/image 3.07 / train/loss/policy -5.1e-3 / train/loss/rep 3.08 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.95

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 357_824]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.08 / train/loss/image 3.06 / train/loss/policy -6.5e-3 / train/loss/rep 3.08 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3294.74

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T131624F785551
Saved checkpoint.

--------------------[Agent Step 359_312]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.07 / train/loss/image 3.05 / train/loss/policy -8.8e-3 / train/loss/rep 3.07 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.32 / fps/train 3153.61

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 360_864]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.09 / train/loss/image 3.07 / train/loss/policy -9.5e-3 / train/loss/rep 3.09 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.34

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 362_416]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.01 / train/loss/image 3 / train/loss/policy -0.01 / train/loss/rep 3.01 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3293.24

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 363_968]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 945.84 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.17 / train/loss/image 3.13 / train/loss/policy -4.9e-3 / train/loss/rep 3.17 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3289.99

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 365_520]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.15 / train/loss/image 3.14 / train/loss/policy -6.4e-3 / train/loss/rep 3.15 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.31

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 367_072]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.04 / train/loss/image 3.06 / train/loss/policy -6.4e-3 / train/loss/rep 3.04 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.85 / fps/train 3290.68

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 368_624]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.04 / train/loss/image 3.06 / train/loss/policy -7.5e-3 / train/loss/rep 3.04 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3295.44

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 370_176]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.09 / train/loss/image 3.06 / train/loss/policy -0.01 / train/loss/rep 3.09 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.88 / fps/train 3297.3

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl
Saving checkpoint: logdir/dreamer/dmc_walker_walk_20251129_211920/ckpt/20251130T133125F529598
Saved checkpoint.

--------------------[Agent Step 371_664]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3 / train/loss/image 3.01 / train/loss/policy -0.01 / train/loss/rep 3 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.33 / fps/train 3156.59

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 373_216]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.03 / train/loss/image 3 / train/loss/policy -5.5e-3 / train/loss/rep 3.03 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.64

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 374_768]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.03 / train/loss/image 3.03 / train/loss/policy -9.6e-3 / train/loss/rep 3.03 / train/loss/repval 0.9 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.83

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 376_320]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.05 / train/loss/image 3 / train/loss/policy -8.2e-3 / train/loss/rep 3.05 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.54

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 377_872]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.03 / train/loss/image 3.01 / train/loss/policy -0.01 / train/loss/rep 3.03 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.87 / fps/train 3293.46

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 379_424]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
episode/score 937.42 / episode/length 1001 / train/loss/con 0.02 / train/loss/dyn 3.05 / train/loss/image 3 / train/loss/policy -0.01 / train/loss/rep 3.05 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.82 / replay/replay_ratio 260 / fps/policy 12.86 / fps/train 3292.91

Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/metrics.jsonl
Writing metrics: logdir/dreamer/dmc_walker_walk_20251129_211920/scores.jsonl

--------------------[Agent Step 380_976]--------------------
Metrics filtered by: 'score|length|fps|ratio|train/loss/|train/rand/'
train/loss/con 0.02 / train/loss/dyn 3.14 / train/loss/image 3.12 / train/loss/policy -9.4e-3 / train/loss/rep 3.14 / train/loss/repval 0.89 / train/loss/rew 0.61 / train/loss/value 0.83 / replay/replay_ratio 260 / fps/policy 12.88 / fps/train 3296.05

/var/spool/slurmd/job6763746/slurm_script: line 28: 1218991 Killed                  python3 dreamerv3/main.py --logdir $LOGDIR --configs dmc_vision --task dmc_walker_walk

=== Training Complete ===
End time: Sun Nov 30 13:46:34 EST 2025
[2025-11-30T13:46:34.729] error: Detected 1 oom_kill event in StepId=6763746.batch. Some of the step tasks have been OOM Killed.
